## Updated on 2023.04.21

## SAM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2023-04-20**|**Any-to-Any Style Transfer: Making Picasso and Da Vinci Collaborate**|Songhua Liu et.al.|[2304.09728v2](http://arxiv.org/abs/2304.09728v2)|**[link](https://github.com/huage001/transfer-any-style)**|
|**2023-04-18**|**Accuracy of Segment-Anything Model (SAM) in medical image segmentation tasks**|Sheng He et.al.|[2304.09324v1](http://arxiv.org/abs/2304.09324v1)|null|
|**2023-04-19**|**SAM Fails to Segment Anything? -- SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More**|Tianrun Chen et.al.|[2304.09148v2](http://arxiv.org/abs/2304.09148v2)|null|
|**2023-04-17**|**When SAM Meets Medical Images: An Investigation of Segment Anything Model (SAM) on Multi-phase Liver Tumor Segmentation**|Chuanfei Hu et.al.|[2304.08506v1](http://arxiv.org/abs/2304.08506v1)|null|
|**2023-04-17**|**Learning to "Segment Anything" in Thermal Infrared Images through Knowledge Distillation with a Large Scale Dataset SATIR**|Junzhang Chen et.al.|[2304.07969v1](http://arxiv.org/abs/2304.07969v1)|**[link](https://github.com/chenjzbuaa/satir)**|
|**2023-04-16**|**The Segment Anything foundation model achieves favorable brain tumor autosegmentation accuracy on MRI to support radiotherapy treatment planning**|Florian Putz et.al.|[2304.07875v1](http://arxiv.org/abs/2304.07875v1)|null|
|**2023-04-16**|**Deep learning universal crater detection using Segment Anything Model (SAM)**|Iraklis Giannakis et.al.|[2304.07764v1](http://arxiv.org/abs/2304.07764v1)|null|
|**2023-04-15**|**Can SAM Segment Polyps?**|Tao Zhou et.al.|[2304.07583v1](http://arxiv.org/abs/2304.07583v1)|null|
|**2023-04-13**|**Inpaint Anything: Segment Anything Meets Image Inpainting**|Tao Yu et.al.|[2304.06790v1](http://arxiv.org/abs/2304.06790v1)|**[link](https://github.com/geekyutao/inpaint-anything)**|
|**2023-04-15**|**SAM Struggles in Concealed Scenes -- Empirical Study on "Segment Anything"**|Ge-Peng Ji et.al.|[2304.06022v2](http://arxiv.org/abs/2304.06022v2)|null|
|**2023-04-13**|**Segment Anything Is Not Always Perfect: An Investigation of SAM on Different Real-world Applications**|Wei Ji et.al.|[2304.05750v2](http://arxiv.org/abs/2304.05750v2)|null|
|**2023-04-12**|**CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks**|Yi Li et.al.|[2304.05653v1](http://arxiv.org/abs/2304.05653v1)|**[link](https://github.com/xmed-lab/clip_surgery)**|
|**2023-04-12**|**SAMM (Segment Any Medical Model): A 3D Slicer Integration to SAM**|Yihao Liu et.al.|[2304.05622v1](http://arxiv.org/abs/2304.05622v1)|**[link](https://github.com/bingogome/samm)**|
|**2023-04-10**|**SAM.MD: Zero-shot medical image segmentation capabilities of the Segment Anything Model**|Saikat Roy et.al.|[2304.05396v1](http://arxiv.org/abs/2304.05396v1)|null|
|**2023-04-19**|**SAM vs BET: A Comparative Study for Brain Extraction and Segmentation of Magnetic Resonance Images using Deep Learning**|Sovesh Mohapatra et.al.|[2304.04738v3](http://arxiv.org/abs/2304.04738v3)|null|
|**2023-04-11**|**Can SAM Segment Anything? When SAM Meets Camouflaged Object Detection**|Lv Tang et.al.|[2304.04709v2](http://arxiv.org/abs/2304.04709v2)|**[link](https://github.com/luckybird1994/samcod)**|
|**2023-04-09**|**Segment Anything Model (SAM) for Digital Pathology: Assess Zero-shot Segmentation on Whole Slide Imaging**|Ruining Deng et.al.|[2304.04155v1](http://arxiv.org/abs/2304.04155v1)|null|
|**2023-04-05**|**Segment Anything**|Alexander Kirillov et.al.|[2304.02643v1](http://arxiv.org/abs/2304.02643v1)|**[link](https://github.com/facebookresearch/segment-anything)**|
|**2020-04-01**|**Towards Segmenting Anything That Moves**|Achal Dave et.al.|[1902.03715v4](http://arxiv.org/abs/1902.03715v4)|null|

