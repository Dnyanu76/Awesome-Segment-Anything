## Updated on 2023.11.03

## SAM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2023-11-02**|**Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning for Medical Image Captioning**|Gaoang Wang et.al.|[2311.01004v1](http://arxiv.org/abs/2311.01004v1)|null|
|**2023-10-31**|**Joint Depth Prediction and Semantic Segmentation with Multi-View SAM**|Mykhailo Shvets et.al.|[2311.00134v1](http://arxiv.org/abs/2311.00134v1)|null|
|**2023-10-31**|**Team I2R-VI-FF Technical Report on EPIC-KITCHENS VISOR Hand Object Segmentation Challenge 2023**|Fen Fang et.al.|[2310.20120v1](http://arxiv.org/abs/2310.20120v1)|null|
|**2023-10-31**|**Promise:Prompt-driven 3D Medical Image Segmentation Using Pretrained Image Foundation Models**|Hao Li et.al.|[2310.19721v2](http://arxiv.org/abs/2310.19721v2)|null|
|**2023-10-30**|**A High-Resolution Dataset for Instance Detection with Multi-View Instance Capture**|Qianqian Shen et.al.|[2310.19257v1](http://arxiv.org/abs/2310.19257v1)|null|
|**2023-10-28**|**Audio-Visual Instance Segmentation**|Ruohao Guo et.al.|[2310.18709v1](http://arxiv.org/abs/2310.18709v1)|null|
|**2023-10-28**|**One-shot Localization and Segmentation of Medical Images with Foundation Models**|Deepa Anand et.al.|[2310.18642v1](http://arxiv.org/abs/2310.18642v1)|null|
|**2023-10-26**|**Task-driven Prompt Evolution for Foundation Models**|Rachana Sathish et.al.|[2310.17128v1](http://arxiv.org/abs/2310.17128v1)|null|
|**2023-10-25**|**SonoSAM -- Segment Anything on Ultrasound Images**|Hariharan Ravishankar et.al.|[2310.16872v1](http://arxiv.org/abs/2310.16872v1)|null|
|**2023-10-25**|**Open-NeRF: Towards Open Vocabulary NeRF Decomposition**|Hao Zhang et.al.|[2310.16383v1](http://arxiv.org/abs/2310.16383v1)|null|
|**2023-10-23**|**SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding**|Haoxiang Wang et.al.|[2310.15308v1](http://arxiv.org/abs/2310.15308v1)|null|
|**2023-10-29**|**SAM-Med3D**|Haoyu Wang et.al.|[2310.15161v2](http://arxiv.org/abs/2310.15161v2)|**[link](https://github.com/uni-medical/sam-med3d)**|
|**2023-10-19**|**Weakly-Supervised Semantic Segmentation with Image-Level Labels: from Traditional Models to Foundation Models**|Zhaozheng Chen et.al.|[2310.13026v1](http://arxiv.org/abs/2310.13026v1)|null|
|**2023-10-04**|**Comprehensive Multimodal Segmentation in Medical Imaging: Combining YOLOv8 with SAM and HQ-SAM Models**|Sumit Pandey et.al.|[2310.12995v1](http://arxiv.org/abs/2310.12995v1)|null|
|**2023-10-19**|**Segment Anything Meets Universal Adversarial Perturbation**|Dongshen Han et.al.|[2310.12431v1](http://arxiv.org/abs/2310.12431v1)|null|
|**2023-10-17**|**Towards Training-free Open-world Segmentation via Image Prompting Foundation Models**|Lv Tang et.al.|[2310.10912v1](http://arxiv.org/abs/2310.10912v1)|null|
|**2023-10-16**|**Evaluation and improvement of Segment Anything Model for interactive histopathology image segmentation**|SeungKyu Kim et.al.|[2310.10493v1](http://arxiv.org/abs/2310.10493v1)|null|
|**2023-10-16**|**Recursive Segmentation Living Image: An eXplainable AI (XAI) Approach for Computing Structural Beauty of Images or the Livingness of Space**|Yao Qianxiang et.al.|[2310.10149v1](http://arxiv.org/abs/2310.10149v1)|null|
|**2023-10-16**|**Black-box Targeted Adversarial Attack on Segment Anything (SAM)**|Sheng Zheng et.al.|[2310.10010v1](http://arxiv.org/abs/2310.10010v1)|null|
|**2023-10-24**|**Segment Anything Model for Pedestrian Infrastructure Inventory: Assessing Zero-Shot Segmentation on Multi-Mode Geospatial Data**|Jiahao Xia et.al.|[2310.09918v3](http://arxiv.org/abs/2310.09918v3)|null|
|**2023-10-17**|**Prototype-oriented Unsupervised Change Detection for Disaster Management**|Youngtack Oh et.al.|[2310.09759v2](http://arxiv.org/abs/2310.09759v2)|null|
|**2023-10-13**|**Generative AI-driven Semantic Communication Framework for NextG Wireless Network**|Avi Deb Raha et.al.|[2310.09021v1](http://arxiv.org/abs/2310.09021v1)|null|
|**2023-10-12**|**Virtual Augmented Reality for Atari Reinforcement Learning**|Christian A. Schiller et.al.|[2310.08683v1](http://arxiv.org/abs/2310.08683v1)|**[link](https://github.com/c-a-schiller/var4arl)**|
|**2023-10-12**|**Fine-Grained Annotation for Face Anti-Spoofing**|Xu Chen et.al.|[2310.08142v1](http://arxiv.org/abs/2310.08142v1)|null|
|**2023-10-11**|**SAM-OCTA: Prompting Segment-Anything for OCTA Image Segmentation**|Xinrun Chen et.al.|[2310.07183v1](http://arxiv.org/abs/2310.07183v1)|**[link](https://github.com/shellredia/sam-octa)**|
|**2023-10-10**|**Machine Eye for Defects: Machine Learning-Based Solution to Identify and Characterize Topological Defects in Textured Images of Nematic Materials**|Haijie Ren et.al.|[2310.06406v1](http://arxiv.org/abs/2310.06406v1)|null|
|**2023-10-09**|**Empirical Evaluation of the Segment Anything Model (SAM) for Brain Tumor Segmentation**|Mohammad Peivandi et.al.|[2310.06162v1](http://arxiv.org/abs/2310.06162v1)|null|
|**2023-10-07**|**Tree-GPT: Modular Large Language Model Expert System for Forest Remote Sensing Image Understanding and Interactive Analysis**|Siqi Du et.al.|[2310.04698v1](http://arxiv.org/abs/2310.04698v1)|null|
|**2023-10-06**|**TiC: Exploring Vision Transformer in Convolution**|Song Zhang et.al.|[2310.04134v1](http://arxiv.org/abs/2310.04134v1)|**[link](https://github.com/zs670980918/msa-conv)**|
|**2023-10-03**|**Multi-Prompt Fine-Tuning of Foundation Models for Enhanced Medical Image Segmentation**|Xiangru Li et.al.|[2310.02381v1](http://arxiv.org/abs/2310.02381v1)|null|
|**2023-10-03**|**Zero-Shot Refinement of Buildings' Segmentation Models using SAM**|Ali Mayladan et.al.|[2310.01845v1](http://arxiv.org/abs/2310.01845v1)|null|
|**2023-10-01**|**Propagating Semantic Labels in Video Data**|David Balaban et.al.|[2310.00783v1](http://arxiv.org/abs/2310.00783v1)|null|
|**2023-09-30**|**Exploring SAM Ablations for Enhancing Medical Segmentation in Radiology and Pathology**|Amin Ranem et.al.|[2310.00504v1](http://arxiv.org/abs/2310.00504v1)|null|
|**2023-10-02**|**UniQuadric: A SLAM Backend for Unknown Rigid Object 3D Tracking and Light-Weight Modeling**|Linghao Yang et.al.|[2309.17036v2](http://arxiv.org/abs/2309.17036v2)|null|
|**2023-09-29**|**Segment Anything Model is a Good Teacher for Local Feature Learning**|Jingqian Wu et.al.|[2309.16992v1](http://arxiv.org/abs/2309.16992v1)|**[link](https://github.com/vignywang/samfeat)**|
|**2023-10-02**|**nnSAM: Plug-and-play Segment Anything Model Improves nnUNet Performance**|Yunxiang Li et.al.|[2309.16967v2](http://arxiv.org/abs/2309.16967v2)|**[link](https://github.com/kent0n-li/medical-image-segmentation)**|
|**2023-09-27**|**Learning from SAM: Harnessing a Segmentation Foundation Model for Sim2Real Domain Adaptation through Regularization**|Mayara E. Bonani et.al.|[2309.15562v1](http://arxiv.org/abs/2309.15562v1)|null|
|**2023-09-24**|**A SAM-based Solution for Hierarchical Panoptic Segmentation of Crops and Weeds Competition**|Khoa Dang Nguyen et.al.|[2309.13578v1](http://arxiv.org/abs/2309.13578v1)|null|
|**2023-09-24**|**MediViSTA-SAM: Zero-shot Medical Video Analysis with Spatio-temporal SAM Adaptation**|Sekeun Kim et.al.|[2309.13539v1](http://arxiv.org/abs/2309.13539v1)|null|
|**2023-09-22**|**NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything**|Xiaobao Wei et.al.|[2309.12790v1](http://arxiv.org/abs/2309.12790v1)|null|
|**2023-09-22**|**PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion**|Yuxiang Yan et.al.|[2309.12708v1](http://arxiv.org/abs/2309.12708v1)|null|
|**2023-09-21**|**Deshadow-Anything: When Segment Anything Model Meets Zero-shot shadow removal**|Xiao Feng Zhang et.al.|[2309.11715v1](http://arxiv.org/abs/2309.11715v1)|null|
|**2023-09-18**|**An Accurate and Efficient Neural Network for OCTA Vessel Segmentation and a New Dataset**|Haojian Ning et.al.|[2309.09483v1](http://arxiv.org/abs/2309.09483v1)|**[link](https://github.com/nhjydywd/octa-frnet)**|
|**2023-09-16**|**MA-SAM: Modality-agnostic SAM Adaptation for 3D Medical Image Segmentation**|Cheng Chen et.al.|[2309.08842v1](http://arxiv.org/abs/2309.08842v1)|**[link](https://github.com/cchen-cc/ma-sam)**|
|**2023-09-15**|**Segment Anything Model for Brain Tumor Segmentation**|Peng Zhang et.al.|[2309.08434v1](http://arxiv.org/abs/2309.08434v1)|null|
|**2023-09-13**|**SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation**|Xian Lin et.al.|[2309.06824v1](http://arxiv.org/abs/2309.06824v1)|**[link](https://github.com/xianlin7/samus)**|
|**2023-09-07**|**SAM3D: Segment Anything Model in Volumetric Medical Images**|Nhat-Tan Bui et.al.|[2309.03493v1](http://arxiv.org/abs/2309.03493v1)|**[link](https://github.com/DinhHieuHoang/SAM3D)**|
|**2023-09-05**|**Artificial General Intelligence for Radiation Oncology**|Chenbin Liu et.al.|[2309.02590v1](http://arxiv.org/abs/2309.02590v1)|null|
|**2023-09-05**|**SAM-Deblur: Let Segment Anything Boost Image Deblurring**|Siwei Li et.al.|[2309.02270v1](http://arxiv.org/abs/2309.02270v1)|**[link](https://github.com/hplqaq/sam-deblur)**|
|**2023-09-04**|**Prompt me a Dataset: An investigation of text-image prompting for historical image dataset creation using foundation models**|Hassan El-Hajj et.al.|[2309.01674v1](http://arxiv.org/abs/2309.01674v1)|**[link](https://github.com/hassanhajj910/prompt-me-a-dataset)**|
|**2023-10-16**|**Adapting Segment Anything Model for Change Detection in HR Remote Sensing Images**|Lei Ding et.al.|[2309.01429v3](http://arxiv.org/abs/2309.01429v3)|**[link](https://github.com/ggsding/sam-cd)**|
|**2023-09-01**|**Self-Sampling Meta SAM: Enhancing Few-shot Medical Image Segmentation with Meta-Learning**|Yiming Zhang et.al.|[2308.16466v2](http://arxiv.org/abs/2308.16466v2)|null|
|**2023-08-30**|**SAM-Med2D**|Junlong Cheng et.al.|[2308.16184v1](http://arxiv.org/abs/2308.16184v1)|**[link](https://github.com/OpenGVLab/SAM-Med2D)**|
|**2023-08-28**|**Auto-Prompting SAM for Mobile Friendly 3D Medical Image Segmentation**|Chengyin Li et.al.|[2308.14936v1](http://arxiv.org/abs/2308.14936v1)|null|
|**2023-08-31**|**SAM-PARSER: Fine-tuning SAM Efficiently by Parameter Space Reconstruction**|Zelin Peng et.al.|[2308.14604v2](http://arxiv.org/abs/2308.14604v2)|null|
|**2023-08-27**|**Cheap Lunch for Medical Image Segmentation by Fine-tuning SAM on Few Exemplars**|Weijia Feng et.al.|[2308.14133v1](http://arxiv.org/abs/2308.14133v1)|null|
|**2023-08-27**|**Enhancing Bloodstain Analysis Through AI-Based Segmentation: Leveraging Segment Anything Model for Crime Scene Investigation**|Zihan Dong et.al.|[2308.13979v1](http://arxiv.org/abs/2308.13979v1)|**[link](https://github.com/zdong104/bloodstain_analysis_ai_tool)**|
|**2023-08-26**|**Zero-Shot Edge Detection with SCESAME: Spectral Clustering-based Ensemble for Segment Anything Model Estimation**|Hiroaki Yamagiwa et.al.|[2308.13779v1](http://arxiv.org/abs/2308.13779v1)|**[link](https://github.com/ymgw55/scesame)**|
|**2023-08-26**|**SamDSK: Combining Segment Anything Model with Domain-Specific Knowledge for Semi-Supervised Learning in Medical Image Segmentation**|Yizhe Zhang et.al.|[2308.13759v1](http://arxiv.org/abs/2308.13759v1)|**[link](https://github.com/yizhezhang2000/samdsk)**|
|**2023-08-25**|**Interactive segmentation in aerial images: a new benchmark and an open access web-based tool**|Zhe Wang et.al.|[2308.13174v1](http://arxiv.org/abs/2308.13174v1)|null|
|**2023-08-23**|**Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion**|Junjiao Tian et.al.|[2308.12469v1](http://arxiv.org/abs/2308.12469v1)|null|
|**2023-08-23**|**SPPNet: A Single-Point Prompt Network for Nuclei Image Segmentation**|Qing Xu et.al.|[2308.12231v1](http://arxiv.org/abs/2308.12231v1)|**[link](https://github.com/xq141839/sppnet)**|
|**2023-08-22**|**SAMSNeRF: Segment Anything Model (SAM) Guides Dynamic Surgical Scene Reconstruction by Neural Radiance Field (NeRF)**|Ange Lou et.al.|[2308.11774v1](http://arxiv.org/abs/2308.11774v1)|null|
|**2023-08-20**|**False Negative/Positive Control for SAM on Noisy Medical Images**|Xing Yao et.al.|[2308.10382v1](http://arxiv.org/abs/2308.10382v1)|null|
|**2023-08-31**|**SAMedOCT: Adapting Segment Anything Model (SAM) for Retinal OCT**|Botond Fazekas et.al.|[2308.09331v2](http://arxiv.org/abs/2308.09331v2)|null|
|**2023-08-17**|**SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation**|Wenxi Yue et.al.|[2308.08746v1](http://arxiv.org/abs/2308.08746v1)|**[link](https://github.com/wenxi-yue/surgicalsam)**|
|**2023-08-15**|**Dancing Avatar: Pose and Text-Guided Human Motion Videos Synthesis with Image Diffusion Model**|Bosheng Qin et.al.|[2308.07749v1](http://arxiv.org/abs/2308.07749v1)|null|
|**2023-08-15**|**Self-Prompting Large Vision Models for Few-Shot Medical Image Segmentation**|Qi Wu et.al.|[2308.07624v1](http://arxiv.org/abs/2308.07624v1)|**[link](https://github.com/peteryyzhang/few-shot-self-prompt-sam)**|
|**2023-08-14**|**SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation**|An Wang et.al.|[2308.07156v1](http://arxiv.org/abs/2308.07156v1)|null|
|**2023-08-14**|**A One Stop 3D Target Reconstruction and multilevel Segmentation Method**|Jiexiong Xu et.al.|[2308.06974v1](http://arxiv.org/abs/2308.06974v1)|**[link](https://github.com/ganlab/ostra)**|
|**2023-08-14**|**CEmb-SAM: Segment Anything Model with Condition Embedding for Joint Learning from Heterogeneous Datasets**|Dongik Shin et.al.|[2308.06957v1](http://arxiv.org/abs/2308.06957v1)|null|
|**2023-08-28**|**CLE Diffusion: Controllable Light Enhancement Diffusion Model**|Yuyang Yin et.al.|[2308.06725v2](http://arxiv.org/abs/2308.06725v2)|null|
|**2023-08-12**|**Polyp-SAM++: Can A Text Guided SAM Perform Better for Polyp Segmentation?**|Risab Biswas et.al.|[2308.06623v1](http://arxiv.org/abs/2308.06623v1)|**[link](https://github.com/RisabBiswas/Polyp-SAM-PlusPlus)**|
|**2023-08-12**|**TongueSAM: An Universal Tongue Segmentation Model Based on SAM with Zero-Shot**|Shan Cao et.al.|[2308.06444v1](http://arxiv.org/abs/2308.06444v1)|**[link](https://github.com/cshan-github/tonguesam)**|
|**2023-08-11**|**FoodSAM: Any Food Segmentation**|Xing Lan et.al.|[2308.05938v1](http://arxiv.org/abs/2308.05938v1)|**[link](https://github.com/jamesjg/foodsam)**|
|**2023-08-10**|**Leverage Weakly Annotation to Pixel-wise Annotation via Zero-shot Segment Anything Model for Molecular-empowered Learning**|Xueyuan Li et.al.|[2308.05785v1](http://arxiv.org/abs/2308.05785v1)|null|
|**2023-08-10**|**Adaptive Low Rank Adaptation of Segment Anything to Salient Object Detection**|Ruikai Cui et.al.|[2308.05426v1](http://arxiv.org/abs/2308.05426v1)|null|
|**2023-08-08**|**AquaSAM: Underwater Image Foreground Segmentation**|Muduo Xu et.al.|[2308.04218v1](http://arxiv.org/abs/2308.04218v1)|null|
|**2023-08-07**|**AdaptiveSAM: Towards Efficient Tuning of SAM for Surgical Scene Segmentation**|Jay N. Paranjape et.al.|[2308.03726v1](http://arxiv.org/abs/2308.03726v1)|**[link](https://github.com/jayparanjape/biastuning)**|
|**2023-08-28**|**Push the Boundary of SAM: A Pseudo-label Correction Framework for Medical Segmentation**|Ziyi Huang et.al.|[2308.00883v2](http://arxiv.org/abs/2308.00883v2)|null|
|**2023-08-16**|**SAMFlow: Eliminating Any Fragmentation in Optical Flow with Segment Anything Model**|Shili Zhou et.al.|[2307.16586v3](http://arxiv.org/abs/2307.16586v3)|null|
|**2023-07-26**|**Tracking Anything in High Quality**|Jiawen Zhu et.al.|[2307.13974v1](http://arxiv.org/abs/2307.13974v1)|**[link](https://github.com/jiawen-zhu/hqtrack)**|
|**2023-07-24**|**Industrial Segment Anything -- a Case Study in Aircraft Manufacturing, Intralogistics, Maintenance, Repair, and Overhaul**|Keno Moenck et.al.|[2307.12674v1](http://arxiv.org/abs/2307.12674v1)|null|
|**2023-08-25**|**CNOS: A Strong Baseline for CAD-based Novel Object Segmentation**|Van Nguyen Nguyen et.al.|[2307.11067v4](http://arxiv.org/abs/2307.11067v4)|**[link](https://github.com/nv-nguyen/cnos)**|
|**2023-07-12**|**SAM-Path: A Segment Anything Model for Semantic Segmentation in Digital Pathology**|Jingwei Zhang et.al.|[2307.09570v1](http://arxiv.org/abs/2307.09570v1)|null|
|**2023-07-15**|**Open Scene Understanding: Grounded Situation Recognition Meets Segment Anything for Helping People with Visual Impairments**|Ruiping Liu et.al.|[2307.07757v1](http://arxiv.org/abs/2307.07757v1)|**[link](https://github.com/ruipingl/opensu)**|
|**2023-09-18**|**$\mathrm{SAM^{Med}}$: A medical image annotation framework based on large vision model**|Chenglong Wang et.al.|[2307.05617v2](http://arxiv.org/abs/2307.05617v2)|null|
|**2023-07-11**|**SAM-U: Multi-box prompts triggered uncertainty estimation for reliable SAM in medical image**|Guoyao Deng et.al.|[2307.04973v1](http://arxiv.org/abs/2307.04973v1)|null|
|**2023-07-10**|**SAM-IQA: Can Segment Anything Boost Image Quality Assessment?**|Xinpeng Li et.al.|[2307.04455v1](http://arxiv.org/abs/2307.04455v1)|**[link](https://github.com/hedlen/sam-iqa)**|
|**2023-07-07**|**Large AI Model-Based Semantic Communications**|Feibo Jiang et.al.|[2307.03492v1](http://arxiv.org/abs/2307.03492v1)|null|
|**2023-07-10**|**ZJU ReLER Submission for EPIC-KITCHEN Challenge 2023: TREK-150 Single Object Tracking**|Yuanyou Xu et.al.|[2307.02508v2](http://arxiv.org/abs/2307.02508v2)|null|
|**2023-07-05**|**AxonCallosumEM Dataset: Axon Semantic Segmentation of Whole Corpus Callosum cross section from EM Images**|Ao Cheng et.al.|[2307.02464v1](http://arxiv.org/abs/2307.02464v1)|null|
|**2023-07-03**|**Segment Anything Meets Point Tracking**|Frano Rajič et.al.|[2307.01197v1](http://arxiv.org/abs/2307.01197v1)|**[link](https://github.com/syscv/sam-pt)**|
|**2023-07-03**|**SAMAug: Point Prompt Augmentation for Segment Anything Model**|Haixing Dai et.al.|[2307.01187v1](http://arxiv.org/abs/2307.01187v1)|null|
|**2023-07-03**|**SAM-DA: UAV Tracks Anything at Night with SAM-Powered Domain Adaptation**|Liangliang Yao et.al.|[2307.01024v1](http://arxiv.org/abs/2307.01024v1)|**[link](https://github.com/vision4robotics/sam-da)**|
|**2023-07-03**|**RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation**|Yonglin Li et.al.|[2307.00997v1](http://arxiv.org/abs/2307.00997v1)|**[link](https://github.com/lancasterli/refsam)**|
|**2023-08-29**|**All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with Prompt-based Finetuning**|Can Cui et.al.|[2307.00290v2](http://arxiv.org/abs/2307.00290v2)|null|
|**2023-08-30**|**Training-free Object Counting with Prompts**|Zenglin Shi et.al.|[2307.00038v2](http://arxiv.org/abs/2307.00038v2)|**[link](https://github.com/shizenglin/training-free-object-counter)**|
|**2023-06-30**|**Topological Data Analysis Guided Segment Anything Model Prompt Optimization for Zero-Shot Segmentation in Biological Imaging**|Ruben Glatt et.al.|[2306.17400v1](http://arxiv.org/abs/2306.17400v1)|null|
|**2023-06-29**|**Detect Any Deepfakes: Segment Anything Meets Face Forgery Detection and Localization**|Yingxin Lai et.al.|[2306.17075v1](http://arxiv.org/abs/2306.17075v1)|**[link](https://github.com/laiyingxin2/dadf)**|
|**2023-06-29**|**The Segment Anything Model (SAM) for Remote Sensing Applications: From Zero to One Shot**|Lucas Prado Osco et.al.|[2306.16623v1](http://arxiv.org/abs/2306.16623v1)|null|
|**2023-06-28**|**RSPrompter: Learning to Prompt for Remote Sensing Instance Segmentation based on Visual Foundation Model**|Keyan Chen et.al.|[2306.16269v1](http://arxiv.org/abs/2306.16269v1)|**[link](https://github.com/KyanChen/RSPrompter)**|
|**2023-06-28**|**Effective Transfer of Pretrained Large Visual Model for Fabric Defect Segmentation via Specifc Knowledge Injection**|Zhewei Chen et.al.|[2306.16186v1](http://arxiv.org/abs/2306.16186v1)|null|
|**2023-06-28**|**Let Segment Anything Help Image Dehaze**|Zheyan Jin et.al.|[2306.15870v1](http://arxiv.org/abs/2306.15870v1)|null|
|**2023-06-24**|**Utilizing Segment Anything Model For Assessing Localization of GRAD-CAM in Medical Imaging**|Evan Kellener et.al.|[2306.15692v1](http://arxiv.org/abs/2306.15692v1)|null|
|**2023-06-27**|**CellViT: Vision Transformers for Precise Cell Segmentation and Classification**|Fabian Hörst et.al.|[2306.15350v1](http://arxiv.org/abs/2306.15350v1)|**[link](https://github.com/tio-ikim/cellvit)**|
|**2023-06-30**|**MedLSAM: Localize and Segment Anything Model for 3D Medical Images**|Wenhui Lei et.al.|[2306.14752v2](http://arxiv.org/abs/2306.14752v2)|**[link](https://github.com/openmedlab/medlsam)**|
|**2023-07-01**|**Faster Segment Anything: Towards Lightweight SAM for Mobile Applications**|Chaoning Zhang et.al.|[2306.14289v2](http://arxiv.org/abs/2306.14289v2)|**[link](https://github.com/chaoningzhang/mobilesam)**|
|**2023-06-25**|**When SAM Meets Sonar Images**|Lin Wang et.al.|[2306.14109v1](http://arxiv.org/abs/2306.14109v1)|**[link](https://github.com/wangsssky/sonarsam)**|
|**2023-06-23**|**How to Efficiently Adapt Large Segmentation Model(SAM) to Medical Images**|Xinrong Hu et.al.|[2306.13731v1](http://arxiv.org/abs/2306.13731v1)|**[link](https://github.com/xhu248/autosam)**|
|**2023-06-23**|**3DSAM-adapter: Holistic Adaptation of SAM from 2D to 3D for Promptable Medical Image Segmentation**|Shizhan Gong et.al.|[2306.13465v1](http://arxiv.org/abs/2306.13465v1)|**[link](https://github.com/med-air/3dsam-adapter)**|
|**2023-06-23**|**Robustness of Segment Anything Model (SAM) for Autonomous Driving in Adverse Weather Conditions**|Xinru Shan et.al.|[2306.13290v1](http://arxiv.org/abs/2306.13290v1)|null|
|**2023-06-22**|**Ladder Fine-tuning approach for SAM integrating complementary network**|Shurong Chai et.al.|[2306.12737v1](http://arxiv.org/abs/2306.12737v1)|**[link](https://github.com/11yxk/sam-lst)**|
|**2023-06-21**|**Comparative Analysis of Segment Anything Model and U-Net for Breast Tumor Detection in Ultrasound and Mammography Images**|Mohsen Ahmadi et.al.|[2306.12510v1](http://arxiv.org/abs/2306.12510v1)|null|
|**2023-06-21**|**Fast Segment Anything**|Xu Zhao et.al.|[2306.12156v1](http://arxiv.org/abs/2306.12156v1)|**[link](https://github.com/casia-iva-lab/fastsam)**|
|**2023-07-04**|**Segment Anything Model (SAM) for Radiation Oncology**|Lian Zhang et.al.|[2306.11730v2](http://arxiv.org/abs/2306.11730v2)|null|
|**2023-07-31**|**Enlighten Anything: When Segment Anything Model Meets Low-Light Image Enhancement**|Qihan Zhao et.al.|[2306.10286v4](http://arxiv.org/abs/2306.10286v4)|**[link](https://github.com/QihanZhao/enlighten-anything)**|
|**2023-06-15**|**Winning Solution for the CVPR2023 Visual Anomaly and Novelty Detection Challenge: Multimodal Prompting for Data-centric Anomaly Detection**|Yunkang Cao et.al.|[2306.09067v1](http://arxiv.org/abs/2306.09067v1)|**[link](https://github.com/caoyunkang/segment-any-anomaly)**|
|**2023-06-15**|**Temporally-Extended Prompts Optimization for SAM in Interactive Medical Image Segmentation**|Chuyun Shen et.al.|[2306.08958v1](http://arxiv.org/abs/2306.08958v1)|null|
|**2023-06-14**|**TomoSAM: a 3D Slicer extension using SAM for tomography segmentation**|Federico Semeraro et.al.|[2306.08609v1](http://arxiv.org/abs/2306.08609v1)|**[link](https://github.com/fsemerar/slicertomosam)**|
|**2023-06-13**|**Robustness of SAM: Segment Anything Under Corruptions and Beyond**|Yu Qiao et.al.|[2306.07713v1](http://arxiv.org/abs/2306.07713v1)|null|
|**2023-06-10**|**AutoSAM: Adapting SAM to Medical Images by Overloading the Prompt Encoder**|Tal Shaharabany et.al.|[2306.06370v1](http://arxiv.org/abs/2306.06370v1)|null|
|**2023-06-21**|**A Survey on Segment Anything Model (SAM): Vision Foundation Model Meets Prompt Engineering**|Chaoning Zhang et.al.|[2306.06211v2](http://arxiv.org/abs/2306.06211v2)|null|
|**2023-06-01**|**SAM-helps-Shadow:When Segment Anything Model meet shadow removal**|Xiaofeng Zhang et.al.|[2306.06113v1](http://arxiv.org/abs/2306.06113v1)|**[link](https://github.com/zhangbaijin/sam-helps-shadow)**|
|**2023-06-08**|**Matting Anything**|Jiachen Li et.al.|[2306.05399v1](http://arxiv.org/abs/2306.05399v1)|**[link](https://github.com/shi-labs/matting-anything)**|
|**2023-06-07**|**Matte Anything: Interactive Natural Image Matting with Segment Anything Models**|Jingfeng Yao et.al.|[2306.04121v1](http://arxiv.org/abs/2306.04121v1)|**[link](https://github.com/hustvl/matte-anything)**|
|**2023-06-06**|**SAM3D: Segment Anything in 3D Scenes**|Yunhan Yang et.al.|[2306.03908v1](http://arxiv.org/abs/2306.03908v1)|**[link](https://github.com/pointcept/segmentanything3d)**|
|**2023-06-06**|**Towards Label-free Scene Understanding by Vision Foundation Models**|Runnan Chen et.al.|[2306.03899v1](http://arxiv.org/abs/2306.03899v1)|**[link](https://github.com/runnanchen/label-free-scene-understanding)**|
|**2023-06-05**|**Calib-Anything: Zero-training LiDAR-Camera Extrinsic Calibration Method Using Segment Anything**|Zhaotong Luo et.al.|[2306.02656v1](http://arxiv.org/abs/2306.02656v1)|**[link](https://github.com/opencalib/calibanything)**|
|**2023-06-06**|**3rd Place Solution for PVUW2023 VSS Track: A Large Model for Semantic Segmentation on VSPW**|Shijie Chang et.al.|[2306.02291v2](http://arxiv.org/abs/2306.02291v2)|**[link](https://github.com/dut-csj/pvuw2023-vss-3rd)**|
|**2023-06-04**|**USD: Unknown Sensitive Detector Empowered by Decoupled Objectness and Segment Anything Model**|Yulin He et.al.|[2306.02275v1](http://arxiv.org/abs/2306.02275v1)|null|
|**2023-06-04**|**SAM3D: Zero-Shot 3D Object Detection via Segment Anything Model**|Dingyuan Zhang et.al.|[2306.02245v1](http://arxiv.org/abs/2306.02245v1)|**[link](https://github.com/dyzhang09/sam3d)**|
|**2023-06-03**|**Segment Anything Meets Semantic Communication**|Shehbaz Tariq et.al.|[2306.02094v1](http://arxiv.org/abs/2306.02094v1)|null|
|**2023-06-02**|**Segment Anything in High Quality**|Lei Ke et.al.|[2306.01567v1](http://arxiv.org/abs/2306.01567v1)|**[link](https://github.com/syscv/sam-hq)**|
|**2023-06-01**|**DeSAM: Decoupling Segment Anything Model for Generalizable Medical Image Segmentation**|Yifan Gao et.al.|[2306.00499v1](http://arxiv.org/abs/2306.00499v1)|**[link](https://github.com/yifangao112/desam)**|
|**2023-06-01**|**Boosting Text-to-Image Diffusion Models with Fine-Grained Semantic Rewards**|Guian Fang et.al.|[2305.19599v2](http://arxiv.org/abs/2305.19599v2)|**[link](https://github.com/enderfga/finerewards)**|
|**2023-05-29**|**InstructEdit: Improving Automatic Masks for Diffusion-based Image Editing With User Instructions**|Qian Wang et.al.|[2305.18047v1](http://arxiv.org/abs/2305.18047v1)|**[link](https://github.com/qianwangx/instructedit)**|
|**2023-05-28**|**AIMS: All-Inclusive Multi-Level Segmentation**|Lu Qi et.al.|[2305.17768v1](http://arxiv.org/abs/2305.17768v1)|**[link](https://github.com/dvlab-research/Entity)**|
|**2023-05-26**|**Detect Any Shadow: Segment Anything for Video Shadow Detection**|Yonghui Wang et.al.|[2305.16698v1](http://arxiv.org/abs/2305.16698v1)|**[link](https://github.com/harrytea/detect-anyshadow)**|
|**2023-05-25**|**Interactive Segment Anything NeRF with Feature Imitation**|Xiaokang Chen et.al.|[2305.16233v1](http://arxiv.org/abs/2305.16233v1)|null|
|**2023-05-25**|**On the Robustness of Segment Anything**|Yihao Huang et.al.|[2305.16220v1](http://arxiv.org/abs/2305.16220v1)|null|
|**2023-05-24**|**SAMScore: A Semantic Structural Similarity Metric for Image Translation Evaluation**|Yunxiang Li et.al.|[2305.15367v1](http://arxiv.org/abs/2305.15367v1)|**[link](https://github.com/kent0n-li/samscore)**|
|**2023-05-23**|**SAD: Segment Any RGBD**|Jun Cen et.al.|[2305.14207v1](http://arxiv.org/abs/2305.14207v1)|**[link](https://github.com/jun-cen/segmentanyrgbd)**|
|**2023-05-23**|**A Dive into SAM Prior in Image Restoration**|Zeyu Xiao et.al.|[2305.13620v1](http://arxiv.org/abs/2305.13620v1)|null|
|**2023-05-22**|**Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching**|Yang Liu et.al.|[2305.13310v1](http://arxiv.org/abs/2305.13310v1)|**[link](https://github.com/aim-uofa/matcher)**|
|**2023-07-02**|**Restore Anything Pipeline: Segment Anything Meets Image Restoration**|Jiaxi Jiang et.al.|[2305.13093v2](http://arxiv.org/abs/2305.13093v2)|**[link](https://github.com/eth-siplab/rap)**|
|**2023-05-22**|**UVOSAM: A Mask-free Paradigm for Unsupervised Video Object Segmentation via Segment Anything Model**|Zhenghao Zhang et.al.|[2305.12659v1](http://arxiv.org/abs/2305.12659v1)|null|
|**2023-05-21**|**BreastSAM: A Study of Segment Anything Model for Breast Tumor Detection in Ultrasound Images**|Mingzhe Hu et.al.|[2305.12447v1](http://arxiv.org/abs/2305.12447v1)|null|
|**2023-05-19**|**When SAM Meets Shadow Detection**|Leiping Jie et.al.|[2305.11513v1](http://arxiv.org/abs/2305.11513v1)|**[link](https://github.com/leipingjie/samshadow)**|
|**2023-05-24**|**Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model**|Siyuan Huang et.al.|[2305.11176v3](http://arxiv.org/abs/2305.11176v3)|**[link](https://github.com/opengvlab/instruct2act)**|
|**2023-05-18**|**Weakly-Supervised Concealed Object Segmentation with SAM-based Pseudo Labeling and Multi-scale Feature Grouping**|Chunming He et.al.|[2305.11003v1](http://arxiv.org/abs/2305.11003v1)|null|
|**2023-05-18**|**Segment Any Anomaly without Training via Hybrid Prompt Regularization**|Yunkang Cao et.al.|[2305.10724v1](http://arxiv.org/abs/2305.10724v1)|**[link](https://github.com/caoyunkang/segment-any-anomaly)**|
|**2023-05-24**|**OR-NeRF: Object Removing from 3D Scenes Guided by Multiview Segmentation with Neural Radiance Fields**|Youtan Yin et.al.|[2305.10503v2](http://arxiv.org/abs/2305.10503v2)|**[link](https://github.com/cuteyyt/or-nerf)**|
|**2023-05-17**|**PromptUNet: Toward Interactive Medical Image Segmentation**|Junde Wu et.al.|[2305.10300v1](http://arxiv.org/abs/2305.10300v1)|**[link](https://github.com/wujunde/promptunet)**|
|**2023-05-17**|**Explain Any Concept: Segment Anything Meets Concept-Based Explanation**|Ao Sun et.al.|[2305.10289v1](http://arxiv.org/abs/2305.10289v1)|null|
|**2023-05-17**|**SAM for Poultry Science**|Xiao Yang et.al.|[2305.10254v1](http://arxiv.org/abs/2305.10254v1)|null|
|**2023-05-22**|**Leaf Only SAM: A Segment Anything Pipeline for Zero-Shot Automated Leaf Segmentation**|Dominic Williams et.al.|[2305.09418v2](http://arxiv.org/abs/2305.09418v2)|**[link](https://github.com/dom3442/leafonlysam)**|
|**2023-05-19**|**A Comprehensive Survey on Segment Anything Model for Vision and Beyond**|Chunhui Zhang et.al.|[2305.08196v2](http://arxiv.org/abs/2305.08196v2)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|
|**2023-05-15**|**Knowledge distillation with Segment Anything (SAM) model for Planetary Geological Mapping**|Sahib Julka et.al.|[2305.07586v2](http://arxiv.org/abs/2305.07586v2)|null|
|**2023-05-11**|**Segment and Track Anything**|Yangming Cheng et.al.|[2305.06558v1](http://arxiv.org/abs/2305.06558v1)|**[link](https://github.com/z-x-yang/segment-and-track-anything)**|
|**2023-05-12**|**Can SAM Boost Video Super-Resolution?**|Zhihe Lu et.al.|[2305.06524v2](http://arxiv.org/abs/2305.06524v2)|null|
|**2023-05-23**|**An Empirical Study on the Robustness of the Segment Anything Model (SAM)**|Yuqing Wang et.al.|[2305.06422v2](http://arxiv.org/abs/2305.06422v2)|null|
|**2023-05-09**|**Segment Anything Model (SAM) Enhanced Pseudo Labels for Weakly Supervised Semantic Segmentation**|Tianle Chen et.al.|[2305.05803v1](http://arxiv.org/abs/2305.05803v1)|**[link](https://github.com/cskyl/sam_wsss)**|
|**2023-06-21**|**How Segment Anything Model (SAM) Boost Medical Image Segmentation: A Survey**|Yichi Zhang et.al.|[2305.03678v2](http://arxiv.org/abs/2305.03678v2)|**[link](https://github.com/yichizhang98/sam4mis)**|
|**2023-05-05**|**BadSAM: Exploring Security Vulnerabilities of SAM via Backdoor Attacks**|Zihan Guan et.al.|[2305.03289v1](http://arxiv.org/abs/2305.03289v1)|null|
|**2023-05-04**|**Personalize Segment Anything Model with One Shot**|Renrui Zhang et.al.|[2305.03048v1](http://arxiv.org/abs/2305.03048v1)|**[link](https://github.com/zrrskywalker/personalize-sam)**|
|**2023-05-08**|**Caption Anything: Interactive Image Description with Diverse Multimodal Controls**|Teng Wang et.al.|[2305.02677v2](http://arxiv.org/abs/2305.02677v2)|**[link](https://github.com/ttengwang/caption-anything)**|
|**2023-05-03**|**Scaling-up Remote Sensing Segmentation Dataset with Segment Anything Model**|Di Wang et.al.|[2305.02034v1](http://arxiv.org/abs/2305.02034v1)|**[link](https://github.com/vitae-transformer/samrs)**|
|**2023-05-03**|**AV-SAM: Segment Anything Model Meets Audio-Visual Localization and Segmentation**|Shentong Mo et.al.|[2305.01836v1](http://arxiv.org/abs/2305.01836v1)|null|
|**2023-05-02**|**An Alternative to WSSS? An Empirical Study of the Segment Anything Model (SAM) on Weakly-Supervised Semantic Segmentation Problems**|Weixuan Sun et.al.|[2305.01586v1](http://arxiv.org/abs/2305.01586v1)|null|
|**2023-05-02**|**Segment Anything is A Good Pseudo-label Generator for Weakly Supervised Semantic Segmentation**|Peng-Tao Jiang et.al.|[2305.01275v1](http://arxiv.org/abs/2305.01275v1)|null|
|**2023-05-08**|**Attack-SAM: Towards Attacking Segment Anything Model With Adversarial Examples**|Chenshuang Zhang et.al.|[2305.00866v2](http://arxiv.org/abs/2305.00866v2)|null|
|**2023-04-29**|**Polyp-SAM: Transfer SAM for Polyp Segmentation**|Yuheng Li et.al.|[2305.00293v1](http://arxiv.org/abs/2305.00293v1)|null|
|**2023-04-29**|**Segment Anything Model (SAM) Meets Glass: Mirror and Transparent Objects Cannot Be Easily Detected**|Dongsheng Han et.al.|[2305.00278v1](http://arxiv.org/abs/2305.00278v1)|null|
|**2023-04-28**|**DSEC-MOS: Segment Any Moving Object with Moving Ego Vehicle**|Zhuyun Zhou et.al.|[2305.00126v1](http://arxiv.org/abs/2305.00126v1)|**[link](https://github.com/zzy-zhou/dsec-mos)**|
|**2023-05-05**|**Zero-shot performance of the Segment Anything Model (SAM) in 2D medical imaging: A comprehensive evaluation and practical guidelines**|Christian Mattjie et.al.|[2305.00109v2](http://arxiv.org/abs/2305.00109v2)|null|
|**2023-04-28**|**SAM on Medical Images: A Comprehensive Study on Three Prompt Modes**|Dongjie Cheng et.al.|[2305.00035v1](http://arxiv.org/abs/2305.00035v1)|null|
|**2023-04-28**|**SAM Meets Robotic Surgery: An Empirical Study in Robustness Perspective**|An Wang et.al.|[2304.14674v1](http://arxiv.org/abs/2304.14674v1)|null|
|**2023-05-19**|**Segment Anything Model for Medical Images?**|Yuhao Huang et.al.|[2304.14660v4](http://arxiv.org/abs/2304.14660v4)|null|
|**2023-04-27**|**Edit Everything: A Text-Guided Generative System for Images Editing**|Defeng Xie et.al.|[2304.14006v1](http://arxiv.org/abs/2304.14006v1)|**[link](https://github.com/defengxie/edit_everything)**|
|**2023-04-27**|**SkinSAM: Empowering Skin Cancer Segmentation with Segment Anything Model**|Mingzhe Hu et.al.|[2304.13973v1](http://arxiv.org/abs/2304.13973v1)|null|
|**2023-04-26**|**GazeSAM: What You See is What You Segment**|Bin Wang et.al.|[2304.13844v1](http://arxiv.org/abs/2304.13844v1)|**[link](https://github.com/ukaukaaaa/gazesam)**|
|**2023-04-26**|**Customized Segment Anything Model for Medical Image Segmentation**|Kaidong Zhang et.al.|[2304.13785v1](http://arxiv.org/abs/2304.13785v1)|**[link](https://github.com/hitachinsk/samed)**|
|**2023-04-26**|**Learnable Ophthalmology SAM**|Zhongxi Qiu et.al.|[2304.13425v1](http://arxiv.org/abs/2304.13425v1)|**[link](https://github.com/qsingle/learnablepromptsam)**|
|**2023-05-15**|**Segment anything, from space?**|Simiao Ren et.al.|[2304.13000v2](http://arxiv.org/abs/2304.13000v2)|null|
|**2023-04-25**|**Generalist Vision Foundation Models for Medical Imaging: A Case Study of Segment Anything Model on Zero-Shot Medical Segmentation**|Peilun Shi et.al.|[2304.12637v1](http://arxiv.org/abs/2304.12637v1)|null|
|**2023-05-13**|**Medical SAM Adapter: Adapting Segment Anything Model for Medical Image Segmentation**|Junde Wu et.al.|[2304.12620v6](http://arxiv.org/abs/2304.12620v6)|**[link](https://github.com/wujunde/medical-sam-adapter)**|
|**2023-04-25**|**Application of Segment Anything Model for Civil Infrastructure Defect Assessment**|Mohsen Ahmadi et.al.|[2304.12600v1](http://arxiv.org/abs/2304.12600v1)|**[link](https://github.com/Gunorta/SegmentAnything_CrackDetection)**|
|**2023-04-26**|**Segment Anything in 3D with NeRFs**|Jiazhong Cen et.al.|[2304.12308v2](http://arxiv.org/abs/2304.12308v2)|null|
|**2023-04-24**|**Segment Anything in Medical Images**|Jun Ma et.al.|[2304.12306v1](http://arxiv.org/abs/2304.12306v1)|**[link](https://github.com/bowang-lab/medsam)**|
|**2023-04-28**|**Track Anything: Segment Anything Meets Videos**|Jinyu Yang et.al.|[2304.11968v2](http://arxiv.org/abs/2304.11968v2)|**[link](https://github.com/gaomingqi/track-anything)**|
|**2023-04-23**|**Segment Anything in Non-Euclidean Domains: Challenges and Opportunities**|Yongcheng Jing et.al.|[2304.11595v1](http://arxiv.org/abs/2304.11595v1)|null|
|**2023-04-22**|**Input Augmentation with SAM: Boosting Medical Image Segmentation with Segmentation Foundation Model**|Yizhe Zhang et.al.|[2304.11332v1](http://arxiv.org/abs/2304.11332v1)|null|
|**2023-04-21**|**Can SAM Count Anything? An Empirical Study on SAM Counting**|Zhiheng Ma et.al.|[2304.10817v1](http://arxiv.org/abs/2304.10817v1)|**[link](https://github.com/vision-intelligence-and-robots-group/count-anything)**|
|**2023-04-20**|**Text2Seg: Remote Sensing Image Semantic Segmentation via Text-Guided Visual Foundation Models**|Jielu Zhang et.al.|[2304.10597v1](http://arxiv.org/abs/2304.10597v1)|**[link](https://github.com/douglas2code/text2seg)**|
|**2023-05-17**|**Segment Anything Model for Medical Image Analysis: an Experimental Study**|Maciej A. Mazurowski et.al.|[2304.10517v3](http://arxiv.org/abs/2304.10517v3)|**[link](https://github.com/mazurowski-lab/segment-anything-medical-evaluation)**|
|**2023-04-19**|**Anything-3D: Towards Single-view Anything Reconstruction in the Wild**|Qiuhong Shen et.al.|[2304.10261v1](http://arxiv.org/abs/2304.10261v1)|**[link](https://github.com/anything-of-anything/anything-3d)**|
|**2023-04-20**|**Any-to-Any Style Transfer: Making Picasso and Da Vinci Collaborate**|Songhua Liu et.al.|[2304.09728v2](http://arxiv.org/abs/2304.09728v2)|**[link](https://github.com/huage001/transfer-any-style)**|
|**2023-05-05**|**Computer-Vision Benchmark Segment-Anything Model (SAM) in Medical Images: Accuracy in 12 Datasets**|Sheng He et.al.|[2304.09324v3](http://arxiv.org/abs/2304.09324v3)|null|
|**2023-05-02**|**SAM Fails to Segment Anything? -- SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, Medical Image Segmentation, and More**|Tianrun Chen et.al.|[2304.09148v3](http://arxiv.org/abs/2304.09148v3)|null|
|**2023-05-09**|**When SAM Meets Medical Images: An Investigation of Segment Anything Model (SAM) on Multi-phase Liver Tumor Segmentation**|Chuanfei Hu et.al.|[2304.08506v4](http://arxiv.org/abs/2304.08506v4)|null|
|**2023-04-17**|**Learning to "Segment Anything" in Thermal Infrared Images through Knowledge Distillation with a Large Scale Dataset SATIR**|Junzhang Chen et.al.|[2304.07969v1](http://arxiv.org/abs/2304.07969v1)|**[link](https://github.com/chenjzbuaa/satir)**|
|**2023-04-16**|**The Segment Anything foundation model achieves favorable brain tumor autosegmentation accuracy on MRI to support radiotherapy treatment planning**|Florian Putz et.al.|[2304.07875v1](http://arxiv.org/abs/2304.07875v1)|null|
|**2023-04-16**|**Deep learning universal crater detection using Segment Anything Model (SAM)**|Iraklis Giannakis et.al.|[2304.07764v1](http://arxiv.org/abs/2304.07764v1)|null|
|**2023-04-15**|**Can SAM Segment Polyps?**|Tao Zhou et.al.|[2304.07583v1](http://arxiv.org/abs/2304.07583v1)|null|
|**2023-04-13**|**Inpaint Anything: Segment Anything Meets Image Inpainting**|Tao Yu et.al.|[2304.06790v1](http://arxiv.org/abs/2304.06790v1)|**[link](https://github.com/geekyutao/inpaint-anything)**|
|**2023-04-27**|**SAM Struggles in Concealed Scenes -- Empirical Study on "Segment Anything"**|Ge-Peng Ji et.al.|[2304.06022v3](http://arxiv.org/abs/2304.06022v3)|null|
|**2023-04-13**|**Segment Anything Is Not Always Perfect: An Investigation of SAM on Different Real-world Applications**|Wei Ji et.al.|[2304.05750v2](http://arxiv.org/abs/2304.05750v2)|null|
|**2023-04-12**|**CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks**|Yi Li et.al.|[2304.05653v1](http://arxiv.org/abs/2304.05653v1)|**[link](https://github.com/xmed-lab/clip_surgery)**|
|**2023-04-12**|**SAMM (Segment Any Medical Model): A 3D Slicer Integration to SAM**|Yihao Liu et.al.|[2304.05622v1](http://arxiv.org/abs/2304.05622v1)|**[link](https://github.com/bingogome/samm)**|
|**2023-04-10**|**SAM.MD: Zero-shot medical image segmentation capabilities of the Segment Anything Model**|Saikat Roy et.al.|[2304.05396v1](http://arxiv.org/abs/2304.05396v1)|null|
|**2023-04-19**|**SAM vs BET: A Comparative Study for Brain Extraction and Segmentation of Magnetic Resonance Images using Deep Learning**|Sovesh Mohapatra et.al.|[2304.04738v3](http://arxiv.org/abs/2304.04738v3)|null|
|**2023-04-11**|**Can SAM Segment Anything? When SAM Meets Camouflaged Object Detection**|Lv Tang et.al.|[2304.04709v2](http://arxiv.org/abs/2304.04709v2)|**[link](https://github.com/luckybird1994/samcod)**|
|**2023-04-09**|**Segment Anything Model (SAM) for Digital Pathology: Assess Zero-shot Segmentation on Whole Slide Imaging**|Ruining Deng et.al.|[2304.04155v1](http://arxiv.org/abs/2304.04155v1)|null|
|**2023-04-05**|**Segment Anything**|Alexander Kirillov et.al.|[2304.02643v1](http://arxiv.org/abs/2304.02643v1)|**[link](https://github.com/facebookresearch/segment-anything)**|
|**2020-04-01**|**Towards Segmenting Anything That Moves**|Achal Dave et.al.|[1902.03715v4](http://arxiv.org/abs/1902.03715v4)|null|

